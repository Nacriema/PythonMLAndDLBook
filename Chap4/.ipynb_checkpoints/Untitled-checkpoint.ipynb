{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting meaning features \n",
    "\n",
    "Nếu ta để ý rằng các models thể hiện tốt hơn trên dữ liệu training dataset hơn là trên test dataset, sự quan sát này là ví dụ cho vấn đề **overfitting**. Như đã giới thiệu trong chương 3, **overfitting** có nghĩa là model fits các tham số quá gần với do sự quan sát kỹ lưỡng của nó trong dữ liệu training dataset, nhưng nó không tổng quát hóa tốt đối với dữ liệu mới; ta nói rằng model của ta là **high variance**. Nguyên nhân của overfitting đó là model của ta quá phức tạp đối với dữ liệu training của mình. Những biện pháp phổ biến để giảm thiểu giá trị lỗi tổng quát (**generalization error**) như sau:\n",
    "* Thu thập thêm nhiều dữ liệu train hơn nữa \n",
    "* Thêm vào gía trị phạt **penalty** cho độ complexity thông qua regularization\n",
    "* Chọn một model nào nhỏ hơn với ít tham số hơn\n",
    "* Giảm thiểu số chiều của dữ liệu\n",
    "\n",
    "Thu thập thêm nhiều dữ liệu nữa thông thường là điều không khả thi. Trong chương 6, ta sẽ học một kỹ thuật có ích dùng để kiểm tra xem **ta cần thêm nhiều điểm dữ liệu nữa thì có giúp ích gì hay không**. Trong phần tiếp theo, ta sẽ tiếp cận với cách thông thường để giảm thiểu overfitting thông qua **regularization** và **dimensionality reduction via feature selection**, sẽ dẫn đến làm cho model của ta cần ít tham số để có thể fit được dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 and L2 regularization as penalties against model complexity\n",
    "\n",
    "Nhắc lại là từ chương 3 thì **L2 regularization** là một hướng tiếp cận để giảm thiểu sự phức tạp của model bằng cách phạt các cá thể có trọng số lớn (penalizing large individual weights). Ta định nghĩa chuẩn L2 cho mảng trọng số **w** như sau: \n",
    "\n",
    "L2:     $\\left \\|w  \\right \\|_{2}^{2} = \\sum_{j=1}^{m}w_{j}^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một hướng tiếp cận khác để giảm độ phức tạp của model là sử dụng **L1 regularization**:\n",
    "\n",
    "L1:    $\\left \\|w  \\right \\|_{1} = \\sum_{j=1}^{m}\\left | w_{j} \\right |$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây, ta đơn giản là thay thế giá trị bình phương của các trọng số bởi tổng của các giá trị tuyệt đối của chúng. Ngược lại với L2 regularization, L1 regularization thường thường tạo ra các feature vector rời rạc và phần lớn các feature weights sẽ trở thành zero. Độ thưa (**sparsiy**) có thể hữu ích nếu như chúng ta có dữ liệu với chiều dữ liệu lớn và có nhiều thuộc tính không liên quan với nhau, đặc biệt là trong trường hợp ta có nhiều chiều không liên quan so với số mẫu training examples. Với nghĩa này, L1 regularization được hiểu là kỹ thuật sử dụng cho feature selection.\n",
    "\n",
    "## A geometric interpretation of L2 regularization \n",
    "\n",
    "Như đã đề cập trong phần trước, L2 regularization thêm thuật ngữ là penalty cho hàm cost function và có ảnh hưởng đến kết quả có các giá trị weight values ít biến đổi lớn so với model train sử dụng mà không có thêm cái regularization (hay còn gọi là unregularized cost function).\n",
    "\n",
    "Để có thể hiểu hơn về cách mà L1 regularization tạo ra sự thưa, ta xem xét cái hình vẽ minh họa cho regularization. Ta vẽ 2 đường contours cho hàm cost function lồi với 2 hệ số trọng lượng $w_{1}$ và $w_{2}$.\n",
    "\n",
    "Ở đây, ta sẽ dùng hàm **sum squared error (SSE)** cost function mà ta sử dụng cho Adaline trong chương 2, bởi vì nó hình cầu và dễ vẽ hơn là hàm cost function cho logistic regression; tuy nhiên concept được áp dụng là như nhau. Ghi nhớ rằng mục tiêu của chúng ta đó là tìm bộ số cho các weight coefficients tối thiểu hóa hàm cost function cho training data, được biểu diễn trong hình bên dưới (điểm nằm ở trung tâm của hình ellipse):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](L1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể tưởng tượng rằng regularization là thêm vào trong đó thành phần penalty cho hàm cost function để khuyến khích đi đến điểm weights nhỏ hơn; nói cách khác ta xử phạt các weights lớn. Do đó, bằng cách tăng độ mạnh cho regularization thông qua tham số $\\lambda$ ta chuyển dần những trọng số của ta về 0 và giảm thiểủ sự phụ thuộc của model vào trainning data. Ta sẽ mô phỏng concept này theo hình vẽ mô tả cho L2 penalty:\n",
    "![](L2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm bậc 2 (quadratic) L2 regulation được biểu diễn bằng hình tròn đậm. Ở đây, các hệ số của trọng lượng không được phép vượt quá cái regulation budget, tức là sự kết hợp của các hệ số trong weight không thể nằm ngoài khoảng tô tậm được. Mặc khác, ta vẫn muốn tối ưu hóa hàm cost function. Dưới điều kiện ràng buộc của penalty constrain, nỗ lực lớn nhất của ta đó là chọn một điểm mà hình cầu L2 giao với lại đường contours của hàm cost function mà chưa có thêm penalized. Giá trị của regulation parameter $\\lambda$ càng lớn, thì giá trị cost sẽ tăng nhanh, điều đó sẽ làm cho cái hình cầu L2 nhỏ dần (giải thích cụ thể hơn mình tham khảo tại: [https://stats.stackexchange.com/questions/388642/why-increasing-lambda-parameter-in-l2-regularization-makes-the-co-efficient-valu?answertab=votes#tab-top](https://stats.stackexchange.com/questions/388642/why-increasing-lambda-parameter-in-l2-regularization-makes-the-co-efficient-valu?answertab=votes#tab-top)). Ví dụ, nếu như chúng ta tăng hệ số $\\lambda$ lên vô cùng thì các hệ số weight coefficients sẽ trở về 0, được ký hiệu bởi chấm trung tâm của hình tròn L2. Tóm lại, mục tiêu của ta là cực tiểu hóa tổng của hàm unpenalized cost function và penalty term, có thể được hiểu như là thêm các bias và mong muốn một model mới đơn giản hơn giảm thiểu sự biến thiên trong trường hợp chúng ta thiếu dữ liệu cần thiết để train dữ liệu và fit model của mình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse solutions with L1 regularization\n",
    "\n",
    "Giờ ta thảo luận về L1 regularization và sparsity. Concept chính của L1 regularization cũng tương tự như những gì ta đã thảo luận trong phần trên. Tuy nhiên, bởi vì L1 là tổng của các trị tuyệt đối của những hệ số weight coefficients (nhớ rằng L2 là hàm bậc 2), ta có thể biểu diễn nó dưới dạng hình diamond-shape budget, như hình vẽ bên dưới:\n",
    "![](L1_.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong hình vẽ trên, ta có thể thấy được đường contour của hàm cost function chạm đến hàm L1 diamond tại w1 = 0. Bởi vì đường contour của L1 regularized là không trơn, đó gần như là điểm tối ưu, giao nhau giữa đường ellipse của hàm cost-function và đường bao của hàm L1 boundary-là điểm nằm trên các trục tọa độ, do đó L1 khuyến khích những hệ số trong weight về 0.\n",
    "\n",
    "#### L1 regularization and sparsity\n",
    "\n",
    "Chứng minh toán học đằng sau vụ L1 regulartion có thể dẫn đến sparse solutions. Một nguồn sách hay giải thích cho L2 và L1 regulartion được trình bày trong phần 3.4 của cuốn The Elements\n",
    "of Statistical Learning, Trevor Hastie, Robert Tibshirani, and\n",
    "Jerome Friedman, Springer Science+Business Media, 2009. (Mình nên đọc thêm cuốn ni). \n",
    "\n",
    "Và có một phần viết riêng về cái ni trong một inpyb khác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularized models trong sklearn support cho L1 regularization, ta đơn giản là set tham số penalty thành 'l1' để có thể đạt được sparse solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
