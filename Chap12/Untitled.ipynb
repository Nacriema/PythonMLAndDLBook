{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 12: Implementing a Multilayer Artificial Neural Network from Scratch\n",
    "\n",
    "\n",
    "Deep learning có thể hiểu là một trường con của Machine learning tập trung vào việc huấn luyện mạng nhân tạo thông qua nhiều lớp một cách hiệu quả. Trong chương này, ta sẽ học về concept cơ bản của NNs.\n",
    "\n",
    "Những chủ đề trong phần này bao gồm:\n",
    "* Hiểu được concept chung về Multilayer NNs.\n",
    "* Cài đặt hàm backpropagation cơ bản cho quá trình training NN.\n",
    "* Training NNs cơ bản để phân loại hình ảnh.\n",
    "\n",
    "## Modeling complex functions with artificial neural networks\n",
    " \n",
    "Lịch sử của quá trình hình thành NNs, đặc biệt là một giai đoạn gọi là [**AI_Winter**](https://en.wikipedia.org/wiki/AI_winter).\n",
    "\n",
    "Một mô hình NNs bao gồm thằng kiến trúc cũng như là thuật toán để học nó nữa.\n",
    "\n",
    "Nhiều ứng dụng của DNNs được phát triển tại nhiều công ty như:\n",
    "* Facebook's DeepFace\n",
    "* Baidu's DeepSpeech\n",
    "* Google's new language translation service\n",
    "* Novel techniques for drug discovery and toxicity prediction (Toxicity prediction using Deep Learning, T. Unterthiner, A. Mayr, G. Klambauer, and S. Hochreiter, arXiv preprint arXiv:1503.01445, 2015)\n",
    "\n",
    "\n",
    "## Single-layer neural network recap\n",
    "\n",
    "Giới thiệu lại những mô hình Single-Layer NNs được giới thiệu trong chương 2\n",
    "\n",
    "\n",
    "Trong chương 2, ta cài đặt ADALINE để thực hiện bài toán phân loại nhị phân, ta sử dụng Gradient Descent Optimization đẻ học các hệ số trọng lượng của model. Trong mỗi epoch (mỗi lần duyệt hết qua các training trong dữ liệu), ta cập nhật trọng số cho vectorr **w** thông qua luật:\n",
    "\n",
    "$w := w + \\Delta w$ với giá trị $\\Delta w = -\\eta \\triangledown  J(w)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nói cách khác, ta tính toán giá trị Gradient dựa trên toàn bộ dữ liệu train và cập nhật trọng số weitghts bằng cách đi theo hướng ngược lại hướng của vector gradient $\\triangledown J(w)$. Để có thể tìm được trọng số tối ưu cho model, ta tối thiểu hóa hàm mục tiêu của mình đó là hàm được định nghĩa mang tên **Sum of Square Errors (SSE)** ký hiệu cho cost function J(w). Hơn nữam ta nhân Gradient với một hệ số, gọi là **learning rate** $\\eta$, hệ số này phải được lựa chọn kỹ để cân bằng giữa tốc độ học và nguy cơ dẫn đến overshooting global minimum của hàm cost function.\n",
    "\n",
    "Trong Gradient Descent Optimization, ta cập nhật trọng số weights đồng thời sau mỗi Epoch, như ta định nghĩa đó là đạo hàm riêng phần của các $w_{j}$ trong vector **w** như sau: \n",
    "\n",
    "$\\frac{\\partial }{\\partial w_{j}} J(w) = - \\sum_{}^{i}(y^{(i)} - a^{(i)})x_{j}^{(i)}$\n",
    "\n",
    "\n",
    "Với giá trị các $y^{(i)}$ là nhãn đúng của mẫu $x^{(i)}$, và $a^{(i)}$ là giá trị sau khi ra khỏi hàm kích hoạt của neuron, là một hàm linear function trong trường hợp của Adaline.\n",
    "\n",
    "Hơn nữa, ta định nghĩa hàm activation function như sau:\n",
    "\n",
    "$\\phi(z) = z = a$\n",
    "\n",
    "Với z : netinput, là tích vector của mảng các weights kết nối giữa đầu vô và đầu ra\n",
    "\n",
    "$z = \\sum^{}_{j} w_{j}x_{j}=w^{T}x$ \n",
    "\n",
    "\n",
    "Trong khi sử dụng hàm Activation $\\phi(z)$ để tính toán giá trị Update của gradient, ta cài đặt thêm hàm threshold để chuyển các giá trị liên tục thành các giá trị rời rạc nhị phân phục vụ việc dự đoán: \n",
    "\n",
    "$\\hat{y} = 1 (nếu g(z) \\geq 0)hoặc -1$ \n",
    "\n",
    "#### Single-layer naming convention \n",
    "\n",
    "Chú ý rằng mặc dù Adaline bao gồm 2 layers, một cho input và một cho output, nó vẫn được gọi là single-layer network bởi vì nó có 1 liên kết đơn giữa lớp input và output của nó thôi.\n",
    "\n",
    "Ta cũng đã tìm hiểu về trick để tăng tốc độ học lên thông qua phương pháp mang tên **stochastic gradient descent (SGD)**. SGD xấp xỉ hàm cost function từ một mẫu training hoặc là một tập training nhỏ thôi (mini-batch training). Ta tận dụng concept này ở chương sau khi tiếp cận và train Multilayer perceptron (MLP). Ngoài việc học nhanh hơn do có nhiều trọng số được cập nhật thường xuyên hơn so với Gradient Descent - thuộc tính Noisy của nó cũng là một trong những lợi thế khi train multilayer NNs với hàm kích hoạt không tuyến tính, hàm đó không có hàm lồi. Ở đây các giá trị noise thêm vào có thể giúp ta thoát khỏi cực trị địa phương, ta sẽ thảo luận nhiều hơn trong chương này.\n",
    "\n",
    "## Introducing the multilayer neural network architecture\n",
    "\n",
    "Trong phần này, ta sẽ học cách kết nối các neuron đơn lại thành một mô hình đa lớp multilayer feedforward NN; trường hợp đặc biệt của nó là fully connected network còn được gọi là **MLP**.\n",
    "\n",
    "Hình bên dưới minh hoạ cho concept của MLP trong đó chứa 3 layers: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/MLP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP** như hình trên bao gồm một input layer, một hidden layer và một output layer. Mỗi phần tử đơn vị trong hidden layer được kết nối fully connect với lớp input layer, và output layer cũng kết nối fully connect với lại thằng hidden layer. Nếu mô hình có nhiều hơn một hidden layer, ta gọi nó là **deep artificial NN**.\n",
    "\n",
    "\n",
    "\n",
    "#### Adding additional hidden layers \n",
    "\n",
    "Ta có thể thêm bất kỳ số lượng lớp ẩn nào vào trong MLP để có thể tạo ra một kiến trúc sâu hơn. Ta có thể tưởng tượng số lớp và số đơn vị trong mỗi lớp như là các tham số mà ta cần phải chọn sao cho tối ưu cho bài toán cụ thể sử dụng **cross-validation technique** (**Mình sẽ đọc về phần này ở trong chương 6 sau khi xong cái mục ni**)\n",
    "\n",
    "Tuy nhiên rằng, càng nhiều lớp thì cái error gradients được tính toán thông qua hàm backpropagation nó sẽ hội tụ chậm hơn. Vấn đề này đặt ra một thách thức lớn cho các model hiện nay. Đo đó tạo ra các thuật toán đặc biệt được phát triển để có thể train được kiến trúc DNN này; những thuật toán đó được gọi là **deep learning**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong hình ở trên, ký hiệu đơn vị **activation** thứ i của hớp thứ l là $a_{i}^{(l)}$. Ta ký hiệu **in** là input layer, **out** là output layer, h là **hidden layer**. Ví dụ $a_{i}^{(in)}$ là giá trị thứ i trong lớp input layer,$a_{i}^{(h)}$ là đơn vị thứ i trong lớp hidden layer, và $a_{i}^{(out)}$ là đơn vị thứ i trong lớp output. Các giá đơn vị kích hoạt $a_{0}^{(in)}$ và $a_{0}^{(h)}$ được gọi là các bias units, và có giá trị bằng 1. Hàm kích hoạt cho các units trong lớp input layer đơn giản chỉ là đầu vào và cộng thêm với thằng bias unit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/gif.latex?a%5E%7B%28in%29%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%20a_%7B0%7D%5E%7B%28in%29%7D%5C%5C%20a_%7B1%7D%5E%7B%28in%29%7D%5C%5C%20...%5C%5C%20a_%7Bm%7D%5E%7B%28in%29%7D%20%5Cend%7Bbmatrix%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%201%5C%5C%20x_1%5E%7Bin%7D%5C%5C%20...%5C%5C%20x_%7Bm%7D%5E%7B%28in%29%7D%20%5Cend%7Bbmatrix%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notational convention for the bias unit\n",
    "\n",
    "Trong phần sau của chương, ta sẽ cài đặt một MLP sử dụng vectơ riêng để chứa các giá trị bias, làm cho quá trình cài đặt hiệu quả và dễ đọc hơn. Concept này cũng đc sử dụng trong TensorFlow. Tuy nhiên công thức toán sẽ phức tạp hơn. Đây chỉ là một cách trình bày khác hơn thôi, chứ bản chất không có gì thay đổi cả.\n",
    "\n",
    "## Mô tả cấu trúc \n",
    "\n",
    "Mỗi đơn vị trong lớp l được kết nối với toàn bộ các unit khác trong lớp thứ l + 1 thông qua trọng số weight giữa chúng. Ví dụ, sự kết nối giữa thằng đơn vị thứ k trong lớp l với lại đơn vị thứ j trong lớp l + 1 được ký hiệu là $w_k,j^{l}$. Tham khảo lại cái hình phía trước, ta ký hiệu ma trận trọng số kết nối cái input với thằng lớp ẩn là $W^{(h)}$, và ký hiệu thằng ma trận kết nối lớp ẩn với lại thằng ouput là $W^{(out)}$.\n",
    "\n",
    "Trong khi đó mỗi thằng đơn vị trong lớp output layer đảm nhiệm việc phân loại nhị phân, ta sẽ thấy loại tổng quan hơn của NN trong hình bên trên, cho phép chúng ta biểu diễn bài toán phân loại nhiều lớp (multiclass classification) thông qua kỹ thuật tổng quan hóa **one-versus-all(OvA)** technique. Để có thể hiểu hơn nó làm những gì, ta tưởng tượng lại kiểu **one-hot encoding** cho những thằng categorical variable trong chương 4.\n",
    "\n",
    "Ví dụ, ta có thể encode 3 nhãn class labels trong dữ liệu IRIS (0=Setosa, 1=Versicolor, 2=Virginica) như sau: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?0%3D%5Cbegin%7Bbmatrix%7D%201%5C%5C%200%5C%5C%200%20%5Cend%7Bbmatrix%7D%2C%201%3D%20%5Cbegin%7Bbmatrix%7D%200%5C%5C%201%5C%5C%200%20%5Cend%7Bbmatrix%7D%2C%202%3D%5Cbegin%7Bbmatrix%7D%200%5C%5C%200%5C%5C%201%20%5Cend%7Bbmatrix%7D)\n",
    "\n",
    "Kiểu biểu diễn one-hot này cho phép chúng ta xử lý với những bài toán phân loại những lớp kiểu này.\n",
    "\n",
    "Trong phần sau ta sẽ vector hóa những ký hiệu subscript và superscript. Ta tổng hợp lại thằng ma trận trọng số kết nối giữa thăng input và thằng hidden là ma trận $W^{(h)} \\in \\mathbb{R}^{m*d}$, với d là số lượng của thằng node con phía sau (không kể thằng bias) và thằng m là số lượng của thằng input units bao gồm cả bias unit. Bởi vì việc nắm được kiến trúc của thằng này là quan trong, nên ta tổng hợp lại những gì đã trình bày bằng hình vẽ cho MLP 3-4-3 sau:\n",
    "\n",
    "![](./images/343MLP.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation a neural network via forward propagation\n",
    "\n",
    "Trong phần này, ta sẽ mô tả tiến trình mang tên **forward propagation**(lan truyền thẳng) để tính toán giá trị output cho MLP model. Để có thể hiểu hơn concept của việc học một MLP Model, ta tổng hợp quá trình học thông qua 3 bước: \n",
    "1. Bắt đầu tại input layer, ta sử dụng lan truyền thẳng dữ liệu training data qua mạng network để tạo ra output.\n",
    "2. Dựa vào network output, ta tính toán giá trị lỗi mà chúng ta muốn tối thiểu bằng cách sử dụng hàm cost function mà ta sẽ định nghĩa trong phần sau.\n",
    "3. Ta backpropagate cái lỗi đó, tìm cái đạo hàm đối với từng thằng trọng số trong network, và cập nhật lại model.\n",
    "\n",
    "Cuối cùng, khi ta lặp lại các tiến trình này trải qua nhiều Epochs và học các trọng số có trong MLP, ta sẽ sử dụng cái forward propagation để tính toán giá trị output và áp dụng hàm ngưỡng thresh hold function để đạt được cái nhãn dự báo theo kiểu one-hot encoding.\n",
    "\n",
    "Giờ ta mô tả chi tiết các bước của forward propagation để tạo ra output từ những thằng mẫu trong dữ liệu train. Do mỗi đơn vị trong lớp hidden layer được kết nối với tất cả những thằng trong lớp input layer, đầu tiên ta tính gía trị activation unit cho thằng hidden layer $a_{1}^{(h)}$ như sau:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/gif.latex?z_%7B1%7D%5E%7B%28h%29%7D%20%3D%20a_%7B0%7D%5E%7B%28in%29%7Dw_%7B0%2C1%7D%5E%7B%28h%29%7D%20&plus;%20a_%7B1%7D%5E%7B%28in%29%7Dw_%7B1%2C1%7D%5E%7B%28h%29%7D&plus;...%20&plus;%20a_%7Bm%7D%5E%7B%28in%29%7Dw_%7Bm%2C1%7D%5E%7B%28h%29%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/gif.latex?a_%7B1%7D%5E%7Bh%7D%20%3D%20%5Cphi%20%28z_%7B1%7D%5E%7B%28h%29%7D%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tức là giá trị a tại node sau bằng hàm activation của net input của toàn bộ thằng input trước đổ về thằng phía sau của nó, cũng dễ hiểu mà :v)\n",
    "\n",
    "Bổ sung thêm, ở đây $z_1^{(h)}$ là giá trị của net input và $\\phi(*)$ được gị là hàm kích hoạt activation function, hàm này nên phải khác biệt để có thể học đc các trọng số kết nối giữa những thằng neuron sử dụng phương thức Gradient Descent. Để có thể giải được vấn đề phức tạp này như là phân loại hình ảnh, ta sử dụng hàm phi tuyến **nonl-linear** cho model MLP của mình, ví dụ như hàm sigmoid (logistic) activation function mà ta đã được học trong chương 3:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cphi%28z%29%20%3D%20%5Cfrac%7B1%7D%7B1%20&plus;%20e%5E%7B-z%7D%7D)\n",
    "\n",
    "Như ta đã gọi, thì hàm sigmoid có dạng hình chữ S và chiếu một giá trị bất kỳ của net input z sang dạng phân phối logistic trong khoảng từ 0 đến 1, và cắt trục y tại điểm z = 0, được biểu diễn theo hình vẽ:\n",
    "\n",
    "![](./images/Sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP là một trong những dạng NN feedforward. Thuật ngữ **feedforward** liên quan đến sự thật là mỗi lớp đóng vai trò làm đầu vào cho những lớp tiếp theo mà không có vòng lặp giữa chúng, ở phía ngược lại trong **recurrent** NNs - một kiểu kiến trúc ta sẽ thảo luận trong phần sau và thảo luận chi tiết trong chương 16. Thuật ngữ Multilayer perceptron có thể làm chúng ta dễ nhầm lẫn. Do rằng những đơn vị trong từng lớp thực chất là những đơn vị kích họat sigmoid units, không phải là các perceptrons. Ta có thể tưởng tượng là mỗi một neuron trong MLP như là một đơn vị logistic regression units và return lại các giá trị trong khoảng từ 0 đến 1.\n",
    "\n",
    "Để làm cho code dễ đọc và thực thi hiêụ quả hơn, ta sẽ viết hàm activation function dưới dạng phức tạp hơn sử dụng concept của đại số tuyến tính, cho phép chúng ta vectơ hóa cài đặt thuật toán của mình thông qua NumPy thay vì viết những hàm for loop tù: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?z%5E%7B%28h%29%7D%20%3D%20a%5E%7B%28in%29%7DW%5E%7B%28h%29%7D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/gif.latex?a%5E%7B%28h%29%7D%20%3D%20%5Cphi%28z%5E%7B%28h%29%7D%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Tức là thay vì làm những vòng for dài ngoằng để tính toán các phần tử trong matrận thì ta sử dụng thằng có sẵn của NumPy để rút gọn công thức tính lại)\n",
    "\n",
    "Với $a^{(in)}$ là vector 1 * m chiều (một dòng và m cột) và chính là mẫu $x^{(in)}$ có thêm thằng bias ở đầu tiên của mảng\n",
    "\n",
    "$W^{(h)}$ là ma trận m * d chiều với d là số lượng đơn vị units trong lớp ẩn của chúng ta. Sau khi thực hiện phép nhân ma trận, ta được một ma trận mới kích thước 1 * d chiều gọi là net input $z^{(h)}$ để dùng nó áp vào tính giá trị activation $a^{(h)}$ (với $a^{(h)} \\in \\mathbb{R}^{1xd}$).\n",
    "\n",
    "Hơn nữa, ta có thể tổng quát hóa quá trình tính toán này đối với n mẫu trong quá trình train dữ liệu của chúng ta:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?Z%5E%7B%28h%29%7D%20%3D%20A%5E%7B%28in%29%7DW%5E%7B%28h%29%7D)\n",
    "\n",
    "với thằng $A^{(in)}$ bây giờ là ma trận n * m chiều, và phép nhân 2 ma trận sẽ cho ra kết quả ma trận $Z^{(h)}$ là n * d chiều. Cuối cùng, ta áp dụng hàm activation funtion $\\phi(.)$ cho mỗi giá trị của thằng net input và thu được ma trận kích hoạt n * d chiều và là lớp tiếp theo của ta (trong phần này chính là cái lớp output):\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?A%5E%7B%28h%29%7D%20%3D%20%5Cphi%28Z%5E%7B%28h%29%7D%29)\n",
    "\n",
    "Tương tự, ta có thể viết hàm activation function cho giá trị output layer: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?Z%5E%7B%28out%29%7D%20%3D%20A%5E%7B%28h%29%7DW%5E%7B%28out%29%7D)\n",
    "\n",
    "Ở đây, ta nhân một ma trận với kích thước d * t chiều $W^{(out)}$ (t là số lượng output units) với lại ma trận có kích thước n * d chiều $A^{(h)}$ để tại ra ma trận input net n * t chiều $Z^{(out)}$ (các cột trong ma trận được tạo thành là đại diện cho các output của từng mẫu). \n",
    "\n",
    "Cuối cúng, ta áp dụng hàm sigmoid function để có được các giá trị đầu ra liên tục trong khoảng từ 0 đến 1\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?A%5E%7B%28out%29%7D%20%3D%20%5Cphi%20%28Z%5E%7B%28out%29%7D%29)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với $A^{(out)} \\in \\mathbb{R}^{n x t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying handwritten digits\n",
    "\n",
    "Trong phần trước, ta đã trình bày lý thuyết về NNs. Trước khi tiếp tục thảo luận về thuật toán học được giá trị trọng số của MLP model (đó là giai đoạn backpropagation), giờ ta bắt đầu những bước cài đặt đầu tiên\n",
    "\n",
    "#### Additional resource on backpropagation\n",
    "\n",
    "* Lý thuyết về NN khá phức tạp, do đó có thêm những nguồn giải thích cụ thể về thằng NNs này trong chương 6:(http://www.deeplearningbook.org)\n",
    "\n",
    "* Pattern Recognition and Machine Learning, C. M. Bishop and others, Volume 1. Springer New York, 2006\n",
    "\n",
    "* Lecture slides from the deep learning course at the University of Wisconsin–Madison:\n",
    "1. https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L08_logistic_slides.pdf\n",
    "2. https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L09_mlp_slides.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong phần này, ta sẽ cài đặt mô hình NN đầu tiên để phân loại chữ viết tay từ nguồn dữ liệu **Mixed National Institute of Standards and Technology (MNIST)** được xây dựng bởi Yann LeCun và các cộng sự bắt đầu từ năm 1998.\n",
    "\n",
    "## Obtaining and preparing the MNIST dataset\n",
    "\n",
    "Dữ liệu có thể tải về từ (http://yann.lecun.com/exdb/mnist/) và bao gồm 4 files:\n",
    "* Training dataset images\n",
    "* Training dataset labels\n",
    "* Test dataset images\n",
    "* Test dataset labels\n",
    "\n",
    "Dữ liệu training bao hàm chữ viết tay của 250 người, 50% là của sinh viên, và 50% là của nhân viên trong công ty. Chú ý rằng dữ liệu test data chứa dữ liệu viết tay với tỉ lệ tương tự dữ liệu train.\n",
    "\n",
    "Sau khi tải về, sử dụng Linux gzip tool để mà giải nén. Sử dụng command sau:\n",
    "\n",
    "gzip *ubyte.gz -d\n",
    "\n",
    "Ta cũng có thể sử dụng tool bất kỳ để giải nén khi làm việc với môi trường Windows.\n",
    "\n",
    "Hình ảnh được lưu trữ với định dạng byte format, ta sẽ đọc chúng vào trong NumPy và sử dụng để train và Test MLP model. Để thực hiện được việc đó, ta định nghĩa một số hàm helper:\n",
    "\n",
    "(Đoạn code ta có thể tìm thấy trong project đi kèm trong chương này)\n",
    "\n",
    "\n",
    "Phương thức load_mnist trả lại 2 mảng, mảng đầu tiên có kích thước n * m chiều NumPy array, bới n là số mẫu và n là số lượng feature (ở đây là pixels). Dữ liệu train bao gồm 60000 training digits và test data chưa 10000 examples.\n",
    "\n",
    "Hình ảnh trong MNIST dataset là định dạng 28 * 28 pixel, và mỗi pixel là giá trị của grayscale intesity values. Ở đây ta duỗi 28 * 28 pixels thành một mảng vector một chiều, đại diện cho các hàng trong mảng image array (784 features với mỗi một tấm hình). Mảng thứ 2 trả lại mảng các nhãn tương ứng cho các thành phần mình đã đọc được trong dữ liệu train hoặc là test.\n",
    "\n",
    "cách mà chúng ta đọc ảnh cũng khá là lạ: \n",
    "\n",
    "```python \n",
    "magic, n = struct.unpack('>II', lpath.read(8))\n",
    "labels = np.fromfile(lbpath, dtypnp.unit8)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để hiểu cách những dòng code này thực hiện, giờ ta xem xét đến mô tả dữ liệu của MNIST\n",
    "\n",
    "![](./images/Data.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng 2 dòng code trên, đầu tiên ta đọc vào magic number, được mô tả trong bảng trên, cũng như là số lượng mẫu n từ file buffer. Trươc khi ta load chúng vào trong mảng NumPy sử dụng phương thức fromfile. Tham số fmt, '>II' mà ta pass vào trong struct.unpack bao gồm 2 thành phần:\n",
    "* > : Đây là ký hiệu của big-endian- định nghiã thứ tự của các byte được lưu trữ.\n",
    "* I: Đây là ký hiệu của Unsigned Integer\n",
    "\n",
    "Cuối cùng, ta normalized những giá trị pixels trong MNIST về lại khoảng -1 tới 1 (thông thường là 0 đến 255) thông qua bước xử lý sau: \n",
    "\n",
    "```python \n",
    "images = ((images / 255.) - .5) * 2\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lý do ở đây là Gradient-Descent Optimization ổn định hơn dưới những điều kiện mà ta đã tạo ra được,cái này đã được đề cập trong chương 2. Chú ý rằng image mà ta đã scale được là nhờ các phép toán cơ bản, điều này khác với những kỹ thuật scale mà ta đã nói trong chương 2 đó.\n",
    "\n",
    "Ta đã có được các giá trị scaled từ training dataset và sử dụng nó để scale các cột trong training dataset và test dataset. Tuy nhiên, khi làm việc với image pixels, center chúng ở zero và chuyển trạng thái của chúng về khoảng [-1, 1] là thông dụng và được áp dụng rộng rãi trong thực tế.\n",
    "\n",
    "#### Batch normalization \n",
    "\n",
    "Một trong số những trick để cải thiện độ hội tụ của Gradient-based Optimization đó là batch normalization, kỹ thuật này được đề cập trong chường 17. Ta có thể đọc thêm về batch normalization tại nguồn tài liệu này (https://arxiv.org/abs/1502.03167)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bằng cách thực thi đoạn code bên dưới, ta có thể load được 60000 mẫu trains cũng như là 10000 mẫu test. \n",
    "\n",
    "Để quan sát được các mẫu test, ta có thể vẽ một vài tấm hình minh họa cho các số trong khoảng từ 0 đến 9 cũng như là các bản khác nhau của cùng một chữ số.\n",
    "\n",
    "Sau khi qua các bước trên, một ý tưởng tốt hơn là ta save lại các giá trị scaled của các images trong một định dạng mới hơn mà ta có thể load ra một cách nhanh chóng hơn trong Python session để tránh tình trạng quá tải khi mà xử lý dữ liệu lại. Khi chúng ta làm việc với NumPy arrays, một biện pháp hiệu quả và thuận tiện đó là lưu giá trị của các array nhiều chiều đó vào trong đĩa thông qua hàm NumPy savez.\n",
    "Tài liệu chi tiết của nó: (https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html)\n",
    "\n",
    "Hàm savez nó cũng tương tự như cái module Pickle của Python vậy, ta đã sử dụng nó trong chapter 9, nhưng nó tối ưu cho việc lưu trữ các dữ liệu NumPy Arrays. Hàm savez tạo ra một file nén định dạng .npz; ta đọc thêm về nó tại đây (https://docs.scipy.org/doc/numpy/neps/npy-format.html). Hơn nữa, thay vì sử dụng hàm savez, ta có thể sử dụng hàm savez_compressed, nó cũng có cú pháp tương tự như hàm savez, nhưng nó nén dữ liệu lại tốt hơn (chỉ còn lại 22Mb thay vì 400Mb khi dùng với savez). Đoạn code bên dưới mô tả cách lưu dữ liệu train và test data vào trong file mnist_scaled.npz: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể load toàn bộ dữ liệu ra lại thông qua list comprehesion, và cái np.load() này nó trả lại những gì mình đã nén trước đó, thuộc tính files cho phép xem các trường có trong dữ liệu đã được load ra lại.\n",
    "\n",
    "Chú ý rằng những thứ savez_compressed và np.load là không cần thiết cho ví dụ ở đây, tại vì ta đang thực hiện trên dữ liệu không lớn lắm. Nhưng mà trong thực tế thì ta vẫn hay dùng những thằng như vậy lắm.\n",
    "\n",
    "#### Loading MNIST using sklearn \n",
    "\n",
    "Sử dụng sklearn method fetch_openml, ta có thể load được dữ liệu của MNIST một cách thuận tiện. Ví dụ ta có thể sử dụng đoạn code bên dưới để có thể tạo ra 50000 training data set và 10000 test dataset. \n",
    "(Code mình để trong thư mục hiện hành thôi)\n",
    "\n",
    "Chú ý rằng cái phân bổ của MNIST trong training và testing dataset sẽ khác với cách tiếp cận thông thường. Do đó, ta có thể thấy được sự khác biệt nhẹ giữa 2 bộ dữ liệu được tạo bởi 2 cách khác nhau (Ta thấy thằng Sklearn nó chậm quá nên thôi, tải data về rồi chiến là được rồi)\n",
    "\n",
    "\n",
    "## Implementing a multilayer perceptron \n",
    "\n",
    "Trong phần này, ta sẽ cài đặt thằng MLP từ đầu để có thể phân biệt được dữ liệu trong Dataset của chúng ta. Để làm cho mọi thứ đơm giản, ta sẽ cài đặt 1 lớp ẩn thôi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an artificial neural network\n",
    "\n",
    "Phần này trình bày kỹ hơn về cách áp dụng logistic regression mà đã trình bày trong chương 3\n",
    "\n",
    "### Computing the logistic cost function\n",
    "\n",
    "Hàm logistic cost function được cài đặt trong phương thức _compute_cost tương tự với hàm cost function mà ta đã cài đặt trong logistic regression trong chương 3:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?J%28w%29%20%3D%20-%20%5Csum_%7Bi%20%3D%201%7D%5E%7Bn%7Dy%5E%7B%5Bi%5D%7Dlog%28a%5E%7B%5Bi%5D%7D%29&plus;%20%281%20-%20y%5E%7B%5Bi%5D%7D%29log%281-a%5E%7B%5Bi%5D%7D%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây, giá trị $a^{[i]}$ là giá trị sigmoid activation của mẫu thứ i trong dữ liệu, và ta tính toán nó như sau: $a^{[i]} = \\phi(z^{[i]})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chú ý, ký hiệu [i] là chỉ số của mẫu train, không phải là chỉ số của lớp. Giờ ta cho thêm thằng regularization, cho phép ta giảm thiểu overfitting. Hàm L2 được định nghĩa như sau (chú ý là ta không cần phải regularize các giá trị bias units):\n",
    "![](https://latex.codecogs.com/gif.latex?L2%20%3D%20%5Clambda%20%5Cleft%20%5C%7C%20w%20%5Cright%20%5C%7C_%7B2%7D%5E%7B2%7D%20%3D%20%5Clambda%20%5Csum_%7Bj%3D1%7D%5E%7Bm%7Dw_%7Bj%7D%5E%7B2%7D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bằng việc thêm giá trị L2 regularization vào trong hàm logistic cost function, ta có được công thức sau: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?J%28w%29%20%3D%20-%20%5B%5Csum_%7Bi%3D1%7D%5E%7Bn%7Dy%5E%7B%5Bi%5D%7Dlog%28a%5E%7B%5Bi%5D%7D%29&plus;%281%20-%20y%5E%7B%5Bi%5D%7D%29log%281%20-%20a%5E%7B%5Bi%5D%7D%29%5D%20&plus;%20%5Cfrac%7B%5Clambda%7D%7B2%7D%5Cleft%20%5C%7Cw%20%5Cright%20%5C%7C_%7B2%7D%5E%7B2%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tưởng tượng mô hình của ta khi dự đoán kiểu dữ liệu cho thằng dữ liệu có nhãn là 2, thì hàm activation của lớp thứ 3 và target (one hot) tương ứng phải là: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?a%5E%7B%28out%29%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%200.1%5C%5C%200.9%5C%5C%20...%5C%5C%200.3%20%5Cend%7Bbmatrix%7D%2C%20y%20%3D%20%5Cbegin%7Bbmatrix%7D%200%5C%5C%201%5C%5C%20...%5C%5C%200%20%5Cend%7Bbmatrix%7D)\n",
    "\n",
    "Do đó, khi ta muốn tổng quá hàm logistic cost function cho tất cả t các activation units trong network của minh. Thì hàm cost function (khi chưa có regularization) trở thành: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?J%28W%29%20%3D%20-%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20%5Csum_%7Bj%3D1%7D%5E%7Bt%7Dy%5E%7B%5Bi%5D%7Dlog%28a_%7Bj%7D%5E%7B%5Bi%5D%7D%29%20&plus;%20%281%20-%20y_%7Bj%7D%5E%7B%5Bi%5D%7D%29log%281%20-%20a_%7Bj%7D%5E%7B%5Bi%5D%7D%29)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với giá trị [i] ký hiệu cho mẫu thứ i trong dữ liệu training dataset.\n",
    "\n",
    "Hàm cost có thêm regularization có chút phức tạp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural networks via backpropagation\n",
    "\n",
    "Trong phần này, ta nghiên các hàm back propagation hoạt động để update weights trong model MLP của chúng ta, trong code được trình bày đoạn # Backpropagation trong phương thức fit. Trong phần trướcm ta đầu tiên phải apply forward propagation để có thể đạt được activation của output layer, trình bày bằng công thức sau: \n",
    "\n",
    "$Z^{(h)} = A^{(in)}W^{(h)}$ (net input of the hidden layer)\n",
    "\n",
    "$A^{(h)} = \\phi(Z^{(h)})$ (activation of the hidden layer)\n",
    "\n",
    "$Z^{(out)} = A^{(h)}W^{(out)}$ (net input of the output layer)\n",
    "\n",
    "$A^{(out)} = \\phi(Z^{(out)})$ (activation of the hidden layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quá trình này được miêu tả bằng hình vẽ sau: \n",
    "\n",
    "![](images/forward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong pha bacpropagation, ta tính toán giá trị error từ phải sang trái.Ta bắt đầu tính toán giá trị error vector của output layer: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta%20%5E%7B%28out%29%7D%20%3D%20a%5E%7B%28out%29%7D%20-%20y)\n",
    "\n",
    "Với y là vector của true class labels (giá trị trong công thức tương đương với thằng delta_out trong code của mình)\n",
    "\n",
    "Tiếp theo, ta tính giá trị delta cho thằng hidden layer:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta%20%5E%7B%28h%29%7D%20%3D%20%5Cdelta%5E%7B%28out%29%7D%28W%5E%7B%28out%29%7D%29%5E%7BT%7D%20%5Codot%20%5Cfrac%7B%5Cpartial%20%5Cphi%20%28z%5E%7B%28h%29%7D%29%7D%7B%5Cpartial%20z%5E%7B%28h%29%7D%7D)\n",
    "\n",
    "Với giá trị $\\frac{\\partial \\phi (z^{(h)})}{\\partial z^{(h)}$ là đạo hàm của hàm sigmoid activation function, giá trị này được tính bằng công thức sigmoid_derivative_h = a_h * (1. - a_h) trong method fit của NeuralNetMLP: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20%5Cphi%20%28z%5E%7B%28h%29%7D%29%7D%7B%5Cpartial%20z%5E%7B%28h%29%7Dt%20%7D%20%3D%20%28a%5E%7B%28h%29%7D%20%5Codot%20%281-a%5E%7B%28h%29%7D%29%29)\n",
    "\n",
    "Chú ý rằng ký hiệu $\\odot$ là element-wise multiplication. (Hay còn được gọi là Hadamard product).\n",
    "\n",
    "### Note: chứng minh công thức\n",
    "\n",
    "Chứng minh đạo hàm của thằng activation function với biến vào là z (net input):\n",
    "\n",
    "![](images/d_activation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo công thức này ta thấy được $\\phi'(z) = a(1-a)$ với a là giá trị activation tại thằng z. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, ta tính giá trị $\\delta^{(h)}$ tại lớp hidden tính toán như sau: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta%5E%7B%28h%29%7D%20%3D%20%5Cdelta%5E%7B%28out%29%7D%28W%5E%7B%28out%29%7D%29%5E%7BT%7D%20%5Codot%20%28a%5E%7B%28h%29%7D%20%5Codot%20%281%20-%20a%20%5E%7B%28h%29%7D%29%29)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích cho công thức này, ta dùng phép transpose ma trận h * t $W^{(out)}$. Với t là số lượng output class labels (trong bài toán cụ thể là 10) và h là số lượng hidden units. Phép nhân ma trận giữa ma trận n * t $\\delta^{(out)}$ và ma trận t * h (W^{(out)})^{T} cho ra ma trận n * h và thông qua phép nhân hadamard với lại đạo hàm của sigmoid với cùng số chiều là n * h để có được ma trận $\\delta^{(h)}$.\n",
    "\n",
    "Sau đó, khi ta có được giá trị $\\delta$ của các lớp, giờ ta có thể biểu thị gía trị của thằng cost function như sau: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20%7D%7B%5Cpartial%20w_%7Bi%2C%20j%7D%5E%7B%28out%29%7D%7DJ%28W%29%3D%20a_%7Bj%7D%5E%7B%28h%29%7D%5Cdelta_%7Bi%7D%5E%7B%28out%29%7D)\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20%7D%7B%5Cpartial%20w_%7Bi%2C%20j%7D%5E%7B%28h%29%7D%7DJ%28W%29%3D%20a_%7Bj%7D%5E%7B%28in%29%7D%5Cdelta_%7Bi%7D%5E%7B%28h%29%7D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các công thức trên dễ hơn khi ta vectơ hóa chúng lại như sau: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5CDelta%20%5E%7B%28h%29%7D%20%3D%20%28A%5E%7B%28in%29%7D%29%5E%7BT%7D%5Cdelta%5E%7B%28h%29%7D)\n",
    "\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5CDelta%20%5E%7B%28out%29%7D%20%3D%20%28A%5E%7B%28h%29%7D%29%5E%7BT%7D%5Cdelta%5E%7B%28out%29%7D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Và ta thêm thằng regularization vào: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5CDelta%20%5E%7B%28l%29%7D%20%3A%3D%20%5CDelta%5E%7B%28l%29%7D%20&plus;%20%5Clambda%5E%7B%28l%29%7D%20W%5E%7B%28l%29%7D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chú ý rằng những thằng bias unit thông thường không cần phải regularized. Những thằng delta_w_h, delta_b_h, delta_w_out, delta_b_out được trình bày trong code của mình.\n",
    "\n",
    "Cuối cùng, sau khi ta tính toán được giá trị của các gradients, ta có thể cập nhật trọng số bằng cách đi theo hướng ngược lại đối với mỗi layer l: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?W%5E%7B%28l%29%7D%20%3A%3D%20W%5E%7B%28l%29%7D%20-%20%5Ceta%20%5CDelta%5E%7B%28l%29%7D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công thức này được cài đặt trong thực tế sẽ như sau :\n",
    "``` python \n",
    "self.w_h -= self.eta * delta_w_h\n",
    "self.b_h -= self.eta * delta_b_h\n",
    "self.w_out -= self.eta * delta_w_out\n",
    "self.b_out -= self.eta * delta_b_out\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hình ảnh tổng hợp những gì mà thăng backpropagation làm được: \n",
    "\n",
    "![](./images/back.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX \n",
    "\n",
    "## Phụ lục thêm về phần backpropagation này\n",
    "\n",
    "Source:http://neuralnetworksanddeeplearning.com/chap2.html\n",
    "\n",
    "4 công thức cần nhớ về hàm backpropagation:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta%5E%7BL%7D%3D%20%5Cbigtriangledown_%7Ba%7DC%20%5Codot%20%5Csigma%20%27%28z%5E%7BL%7D%29) (BP1)\n",
    "\n",
    "Trong trường hợp của quadratic cost tức là ![](https://latex.codecogs.com/gif.latex?Cost%20%3D%20%5Cfrac%7B1%7D%7B2%7D%28a%5EL%20-%20y%29%5E%7B2%7D), ta có được điều này: ![](https://latex.codecogs.com/gif.latex?%5Cbigtriangledown_%7Ba%7DC%20%3D%20%28a%5E%7BL%7D%20-%20y%29), và do đó công thức tại (BL1) trở thành:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta%5E%7BL%7D%20%3D%20%28a%5E%7BL%7D-y%29%5Codot%20%5Csigma%27%28z%5E%7BL%7D%29)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Công thức cho error trong lớp trước thông qua lớp sau của nó:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta%5E%7Bl%7D%20%3D%20%5Cdelta%5E%7Bl&plus;1%7D%28W%5E%7Bl&plus;1%7D%29%5E%7BT%7D%20%5Codot%20%5Csigma%20%27%28z%5E%7Bl%7D%29)  (BP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Công thức tính lượng thay đổi cost tương ứng với bất kỳ bias nào trong network:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20b_%7Bj%7D%5E%7Bl%7D%7D%20%3D%20%5Cdelta_%7Bj%7D%5E%7Bl%7D)  (BP3)\n",
    "\n",
    "Ta có thể viết lại dạng gọn hơn như sau: \n",
    "![](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20b%7D%20%3D%20%5Cdelta)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Công thức tính lượng thay đổi của cost tương ứng với weight bất kỳ trong network: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20w_j_k%5E%7Bl%7D%7D%20%3D%20a_k%5E%7Bl-1%7D%5Cdelta_j%5El)  (BP4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chứng minh cho 4 công thức cơ bản nói trên \n",
    "\n",
    "* Chứng minh thăng BP1:\n",
    "\n",
    "Theo định nghĩa ta có công thức: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta_j%5EL%3D%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20z_j%5EL%7D)\n",
    "\n",
    "Sau khi áp dụng quy tắc chuối, ta có công thức sau: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta_j%5EL%3D%5Csum%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20a_k%5El%7D%5Cfrac%7B%5Cpartial%20a_k%5EL%7D%7B%5Cpartial%20z_j%5EL%7D)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chú ý rằng thằng output activation $a_k^L$ chỉ phụ thuộc vào thằng net input $z_j^L$ khi mà thằng k = j. Còn lại các giá trị khác chúng ko phụ thuộc vào nhau, tại những điểm đó thì gía trị của thằng $\\frac{\\partial a_k^L}{\\partial z_j^L}$ là bằng 0. Do đó biểu thức có thể rút gọn lại thành: \n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta_j%5EL%3D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20a_j%5El%7D%5Cfrac%7B%5Cpartial%20a_j%5EL%7D%7B%5Cpartial%20z_j%5EL%7D)\n",
    "\n",
    "Mà ta lại có rằng $a_j^L=\\sigma(z_j^L)$ nên là thành phần thứ 2 của biểu thức có thể viết lại thành:\n",
    "\n",
    "![](https://latex.codecogs.com/gif.latex?%5Cdelta_j%5EL%3D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20a_j%5El%7D%5Csigma%27%28z_j%5EL%29)\n",
    "\n",
    "Đây chính là công thức của thằng BP1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Chứng minh thằng BP2:\n",
    "\n",
    "Ta cũng sử dụng chain rule: \n",
    "\n",
    "\n",
    "Phần ni mai tìm hiểu tiếp, mệt cái ni rồi. Chuyển sang cái khác học."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
