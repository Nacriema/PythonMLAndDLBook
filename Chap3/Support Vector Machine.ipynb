{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum margin classification with support vector machines\n",
    "\n",
    "Một trong những thuật toán quan trọng được sử dụng rộng rãi đó là **support vector machine (SVM)**, nó được xem như là một dạng mở rộng của **perceptron**. Khi sử dụng thuật toán của perceptron, ta hướng đến việc tối thiểu hóa **missclassification errors**. Tuy nhiên, trong SVMs thì mục đích của việc tối ưu đó chính là cái margin. Margin được định nghiã là khoảng cách giữa siêu phẳng phân cách - hyperplane (decision boudary) và những mẫu train gần với cái siêu phẳng đó nhất, các điểm đó còn được gọi là các **support vectors**, điều này được mô phỏng bên dưới:\n",
    "\n",
    "\n",
    "![Margin-SVMs](marginVisual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum margin intuition\n",
    "\n",
    "Lý do ta lựa chọn cái phân cách sao cho có được margin lớn nhất là vì khi thực hiện dự đoán, các model có margin nhỏ dễ dấn đến overfitting hơn. Để có được ý tưởng chọn siêu phẳng phân cách có margin lớn nhất, xem xét đến 2 siêu phẳng positive và negative song song với lại mặt phẳng phân cách, được mô tả như sau:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eq1](https://latex.codecogs.com/gif.latex?w_%7B0%7D%20&plus;%20w%5E%7BT%7D%20x_%7Bpos%7D%20%3D%201) \n",
    "\n",
    "![eq2](https://latex.codecogs.com/gif.latex?w_%7B0%7D%20&plus;%20w%5E%7BT%7D%20x_%7Bneg%7D%20%3D%20-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu như ta trừ 2 biểu thức này với nhau, ta sẽ được:\n",
    "\n",
    "![eq3](https://latex.codecogs.com/gif.latex?%5CRightarrow%20w%5E%7BT%7D%28x_%7Bpos%7D%20-%20x_%7Bneg%7D%29%20%3D%202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể chuẩn hóa biểu thức này bằng cách chia hai vế cho chiều dài của vector **w**, được định nghĩa là chuẩn 2 - chuẩn Euclide:\n",
    "\n",
    "![eq4](https://latex.codecogs.com/gif.latex?%5Cleft%20%5C%7C%20w%20%5Cright%20%5C%7C%20%3D%20%5Csqrt%7B%5Csum_%7Bj%3D1%7D%5E%7Bm%7Dw%7B_%7Bj%7D%5E%7B2%7D%7D%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do đó, ta sẽ được biểu thức: \n",
    "\n",
    "![eq5](https://latex.codecogs.com/gif.latex?%5Cfrac%7Bw%5E%7BT%7D%28x_%7Bpos%7D%20-%20x_%7Bneg%7D%29%7D%7B%5Cleft%20%5C%7C%20w%20%5Cright%20%5C%7C%7D%20%3D%20%5Cfrac%7B2%7D%7B%5Cleft%5C%7C%20w%20%5Cright%5C%7C%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vế trái của biểu thức trên là khoảng cách giữa 2 siêu phẳng positive và negative, còn được gọi với tên là **margin** mà chúng ta cần cực đại hóa. Tương đương với việc cực đại biểu thức $\\frac{2}{\\left\\|w\\right\\|}$ với điều kiện ràng buộc là tất cả các mẫu được phân loại đúng, có thể được biểu diễn là: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eq6](https://latex.codecogs.com/gif.latex?w_%7B0%7D%20&plus;%20w%5E%7BT%7Dx%5E%7B%28i%29%7D%20%5Cgeqslant%201)  nếu  $y^{(i)} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eq](https://latex.codecogs.com/gif.latex?w_%7B0%7D%20&plus;%20w%5E%7BT%7Dx%5E%7B%28i%29%7D%20%5Cleqslant%20-1) nếu $y^{(i)} = -1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với i = 1 ... N và N là số mẫu trong dữ liệu train.\n",
    "\n",
    "Hai biểu thức ở trên có nghĩa là các mẫu negative-class nên rơi vào một phía của siêu phẳng negative, và tương tự đối với các mẫu positive. Cả 2 biểu thức trên có thể được biểu diễn dưới dạng tổng quát hơn:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/gif.latex?y%5E%7B%28i%29%7D%28w_%7B0%7D&plus;%20w%5E%7BT%7Dx%5E%7B%28i%29%7D%29%20%5Cgeq%201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong thực tế, ta sẽ tìm cực tiểu của dạng nghịch đảo, tức là ta tìm cực tiểu của bài toán $\\frac{1}{2}\\left \\| w \\right \\|^{2}$, bài toán sẽ được chuyển về dạng tìm cực tiểu của phương trình bậc 2. Tài liệu đọc thêm về SVM, trong cuốn sách này không đi sâu lắm về cái ni:\n",
    "\n",
    "The Nature of Statistical Learning Theory, Springer Science+Business Media, Vladimir\n",
    "Vapnik, 2000, or read Chris J.C. Burges' excellent explanation in A Tutorial on Support\n",
    "Vector Machines for Pattern Recognition (Data Mining and Knowledge Discovery, 2(2):\n",
    "121-167, 1998\n",
    "\n",
    "## Dealing with a nonlinearly separable case using slack variable\n",
    "\n",
    "Đề cập ngắn đến biến slack (biến chùng), $\\xi$, được phát biểu bởi Vladimir Vapnik vào năm 1995, và nó dẫn đến một chủ đề gọi là **soft-margin classification**. Mục đích mà biến này ra đời là do điều kiện phân vùng tuyến tính không cần phải quá khắt khe đối với trường hợp dữ liệu không phải phân chia tuyến tính được, cho phép hội tụ và bỏ qua tính missclassifications, dưới một ngưỡng giá trị penalization (giá trị phạt) là được. \n",
    "\n",
    "Giá trị positive-valued slack variable đơn giản là được thêm vào trong điều kiện ràng buộc\n",
    "\n",
    "$w_{0} + w^{T}x^{(i)} \\geq 1 - \\xi^{(i)}$   nếu $y^{(i)} = 1$ \n",
    "\n",
    "$w_{0} + w^{T}x^{(i)} \\leq -1 + \\xi^{(i)}$   nếu $y^{(i)} = -1$\n",
    "\n",
    "Với i = 1...N\n",
    "\n",
    "Ở đây N là số mẫu trong dataset. Do đó, đối tượng mới mà chúng ta cần tối thiểu hóa trở thành:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eq](https://latex.codecogs.com/gif.latex?%5Cfrac%7B1%7D%7B2%7D%20%5Cleft%20%5C%7C%20w%20%5Cright%20%5C%7C%5E%7B2%7D%20&plus;%20C%28%5Csum_%7Bi%7D%5Cxi%5E%7B%28i%29%7D%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thông qua biến C, ta có thể điều chỉnh được lượng penalty cho phân loại sai. Giá trị C càn lớn thì giá trị error penalty càng lớn, ngược lại sẽ ít strict hơn đối với phân loại sai khi ta chọn giá trị C nhỏ. Từ đó ta có thể dùng tham số C để điều chỉnh được chiều rộng của margin và từ đó sẽ cần bằng được cái gọi là **bias-variance tradeoff**, được minh họa trong hình vẽ sau:\n",
    "\n",
    "![ilus](tradeof.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cái concept này tương đương với **regularization** của mô hình **logistic regression**, nếu như ta giảm giá trị C của nó thì sẽ tăng tính bias và giảm đi sự variance của model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta đã có đc bức tranh cơ bản của SVM, giờ sử dụng SVM để phân loại các loại hoa khác nhau trong dữ liệu dataset của mình.\n",
    "\n",
    "Mình xin trích những đoạn code chính về thao tác với SVM thôi\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "plot_decision_regions(X_combined_std,\n",
    "y_combined,\n",
    "classifier=svm,\n",
    "test_idx=range(105, 150))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ba vùng phân hoạch cho SVM, sau khi chạy đoạn code thì ta có được hình vẽ:\n",
    "\n",
    "![im](svm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Logistic regression vs SVMs\n",
    "\n",
    "Trong thực tế, linear logistic regression và linear SVMs thường cho ra kết quả giống nhau. Logistic regression mục tiêu là cực đại hóa likelihoods của dữ liệu train, tức kết quả nó sát với cái ranh giới phân chia còn SVMs là quan tâm chính tới những điểm gần nhất với ranh giới phân chia (decision boudary) hay còn gọi là những support vector. Ngược lại, logistic regression có ưu điểm ở chỗ là nó đơn giản và cài đặt nó dễ hơn, Hơn nữa, logistic regression model dễ được cập nhật, là điều cực kỳ quan trọng khi xử lý với dòng dữ liệu (online learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative implementation in sklearn\n",
    "\n",
    "Thư viện Sklearn có class LogisticRegression được sử dụng thư viện LIBLINEAR, được tối ưu bằng thư viện C/C++, được phát triển tại đại học National Taiwan University. Tương tự, class SVC dùng cho việc train SVM Model là tận dụng từ thư viện LIBSVM.\n",
    "\n",
    "Lợi ích của sử dụng LIBLINEAR và LIBSVM so với Python thuần đó là nó cho ta tốc độ train dữ liệu nhanh đối với lượng dữ liệu lớn. Tuy nhiên, dữ liệu của chúng ta quá lớn và ko thể nào fit vào cùng một lúc được. Do đó Sklearn cung cấp một phương pháp thay thế khác là sử dụng class SGDClassifier, nó hỗ trợ việc học online learning thông qua method **partial_fit**. Concept đằng sau SGDClassifier tương tự như những gì ta đã cài đặt trong Chapter 2. Ta có thể khởi tạo SGD version của perceptron, logistic regression và SVM bằng tham số mặc định như sau:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "ppn = SGDClassifier(loss='perceptron')\n",
    "lr = SGDClassifier(loss='log')\n",
    "svm = SGDClassifier(loss='hinge')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link tìm hiểu thêm về cái ni: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving nonlinear problems using a kernel SVM\n",
    "\n",
    "Lý do khác làm cho SVMs được ưa chuộng sử dụng trong các thuật toán machine learning đó là nó rất dễ được **kernelized** để giải quyết các bài toán phân loại không tuyến tính. Trước khi thảo luận về concept chính của **kernel SVM** - là một biến thể thường gặp của SVMs, ta hãy tạo dữ liệu để xem xét một bài toán nonlinear classification nó như thế nào.\n",
    "\n",
    "### Kernel methods for linearly inseparable data\n",
    "\n",
    "Sử dụng đoạn code bên dưới, ta sẽ tạo được tập dữ liệu cơ bản là đại diện cho phép toán XOR bằng cách dùng hàm logical_xor của NumPy, 100 mẫu sẽ đc gắn nhãn 1 và 100 mẫu sẽ được gắn nhãn -1:\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "X_xor = np.random.randn(200, 2)\n",
    "y_xor = np.logical_xor(X_xor[:, 0] > 0,\n",
    "X_xor[:, 1] > 0)\n",
    "y_xor = np.where(y_xor, 1, -1)\n",
    "\n",
    "plt.scatter(X_xor[y_xor == 1, 0],\n",
    "            X_xor[y_xor == 1, 1],\n",
    "            c='b', marker='x',\n",
    "            label='1')\n",
    "plt.scatter(X_xor[y_xor == -1, 0],\n",
    "            \n",
    "\n",
    "X_xor[y_xor == -1, 1],\n",
    "            c='r', marker='s',\n",
    "            label='-1')\n",
    "\n",
    "plt.xlim([-3, 3])\n",
    "plt.ylim([-3, 3])\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có được dữ liệu của phép XOR từ các điểm dữ liệu lấy random ban đầu. Rõ ràng là ta không thể phân chia dữ liệu nàỳ bằng việc sử dụng một siêu phẳng tuyến tính thông qua các model linear logistic regression hoặc linear SVM được.\n",
    "\n",
    "Ý tưởng cơ bản của **kernel methods** được dùng để đối mặt với các dữ liệu kiểu như vậy, phương pháp này sử dụng sự kết hợp phi tuyến của các thuộc tính và chiếu chúng lên một không gian nhiều chiều hơn thông qua một hàm chiếu mapping function $\\phi$, nơi mà dữ liệu có thể được phân chia một cách tuyến tính được. Ta có thể xem mô tả trực quan thông qua hình vẽ bên dưới. Như trong hình phía trên, ta có thể biểu diễn dữ liệu 2 chiều này thành dạng dữ liệu 3 chiều mới, nơi mà các class có thể được phân chia thông qua phép chiếu (**projection**) sau:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eq](https://latex.codecogs.com/gif.latex?%5Cphi%28x_%7B1%7D%2C%20x_%7B2%7D%29%20%3D%20%28z_%7B1%7D%2C%20z_%7B2%7D%2C%20z_%7B3%7D%29%20%3D%20%28x_%7B1%7D%2C%20x_%7B2%7D%2C%20x_%7B1%7D%5E%7B2%7D%20&plus;%20x_%7B2%7D%5E%7B2%7D%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điều này cho phép chúng ta phân tách 2 lớp như hình bên dưới trên không gian 3 chiều rồi ta chiếu lại thành không gian 2 chiều và nó trở thành phân loại không tuyến tính:\n",
    "(Hình vẽ minh họa cho tư tưởng chiếu ở trên)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the kernel trick to find separating hyperplanes in a high-dimensional space\n",
    "\n",
    "Để giải quyết vấn đề phân loại không tuyến tính bằng SVM, ra sẽ chuyển dữ liệu training data sang một chiều không gian lớn hơn thông qua hàm mapping function $\\phi$, và train một linear SVM model để phân loại dữ liệu trên chiều không gian mới đó (new features space).\n",
    "\n",
    "Tuy nhiên, một vấn đề xảy đến đối với phương pháp mapping này là việc xây dựng chiều dữ liệu mới tốn nhiều thời gian tính toán, đặc biệt là khi chúng ta đối diện với dữ liệu nhiều chiều. Đây chính là lý do mà chúng ta sử dụng **kernel trick** để giải quyết vấn đề này.\n",
    "\n",
    "Trong tế người ta sẽ thay đổi phép toán tính $x^{(i)T}x^{(j)}$ bởi biểu thức $\\phi(x^{(i)})^{T} \\phi(x^{(j)})$. Để giảm thiểu các bước tính toán giá trị dot product giữa 2 điểm cụ thể, người ta định nghĩa hàm gọi là **kernel function**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eq](https://latex.codecogs.com/gif.latex?k%28x%5E%7B%28i%29%7D%2C%20x%5E%7B%28j%29%7D%29%20%3D%20%5Cphi%28x%5E%7B%28i%29%7D%29%5E%7BT%7D%5Cphi%28x%5E%7B%28j%29%7D%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một trong số những kernel được sử dụng rộng rãi đó là **radial basis function (RBF)** kernel, có có tên đơn giản kà **Gaussian kernel**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/gif.latex?k%28x%5E%7B%28i%29%7D%2C%20x%5E%7B%28j%29%7D%29%20%3D%20exp%28-%5Cfrac%7B%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20x%5E%7B%28j%29%7D%20%5Cright%20%5C%7C%5E%7B2%7D%7D%7B2%5Csigma%20%5E%7B2%7D%7D%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm này thường được đơn giản lại thành:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://latex.codecogs.com/gif.latex?k%28x%5E%7B%28i%29%7D%2C%20x%5E%7B%28j%29%7D%29%20%3D%20exp%28-%5Cgamma%20%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20x%5E%7B%28j%29%7D%20%5Cright%20%5C%7C%5E%7B2%7D%29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với $\\gamma = \\frac{1}{2\\sigma^{2}}$ là tham số cần được tối ưu hóa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một cách nói khác hơn, khái niệm \"kernel\" có thể được nói là một hàm tương tự **similarity function** giữa một cặp điểm. Dấu - nó chuyển khoảng cách đo thành giá trị similarity score, và do hàm mũ exponential, kết quả của hàm similarity này rơi vào trong khoảng 1 (đối với các mẫu giống hệt nhau) và 0 (đối với các mẫu khác hẳn nhau)\n",
    "\n",
    "Ta đã có được ý tưởng chung của kernel trick, giờ xem thử ta có thể train SVM model để có thể vẽ ranh giới phân chia để phân tách dữ liệu XOR bên trên. Ở đây ta sử dụng class từ sklearn và thay thế kernel='linear' thành kernel='rbf':\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.svm import SVC \n",
    "svm = SVC(kernel='rbf', random_state=1, gamma=0.10, C=10.0)\n",
    "svm.fit(X_xor, y_xor)\n",
    "plot_decision_regions(X_xor, y_xor, classifier=svm)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thấy trong kết quả, kernel trong SVM phân chia dữ liệu XOR data khá tốt:\n",
    "\n",
    "![](rbf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giá trị của $\\gamma$ được set là gamma = 0.1, có thể được hiểu là cut-off parametter cho Gaussian sphere. Nếu ta tăng giá trị của $\\gamma$, ta sẽ tăng cường mức độ ảnh hưởng hoặc là tiến dần đến dữ liệu training, sẽ dẫn đến đường phân chia \"khít hơn\". Để tìm hiểu về giá trị của $\\gamma$, ta hãy tăng giá trị của nó lên 100:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](gamma100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mặc dù model fit dữ liệu vô cùng tốt, nhưng mà như ta thấy thì nó cho kết quả tổng quát vô cùng tệ, tức là nó ko có khả năng tổng quát hóa được. Trong mô tả trên thì ta thấy rằng tham số $\\gamma$ đóng vai trò quan trọng trong việc điều chỉnh overfitting hoặc variance khi mà thuật toán nó dễ bị biến đổi trong dữ liệu train của chúng ta.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
